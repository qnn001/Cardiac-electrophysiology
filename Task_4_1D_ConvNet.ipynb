{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorrt\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0585, 0.7011],\n",
      "        [0.2547, 0.9405]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.rand(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/g/g11/quyng/Documents/code/Cardiac-electrophysiology/T3_ansh')\n",
    "import data_dssi as ds # name clash, will import from current folder instead!\n",
    "import utils\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = [0.8, 0.15, 0.05]\n",
    "batch_size = 2 #64\n",
    "\n",
    "data = ds.read_data()\n",
    "ds_data = ds.Custom_dataset(data)\n",
    "\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_ds, val_ds, test_ds = random_split(ds_data, split_size, generator=generator)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Checkpoint\n",
    "print('Train:')\n",
    "for batch in train_loader:\n",
    "    print('Input dimensions:', batch[0].shape)\n",
    "    print('Output dimensions:', batch[1].shape)\n",
    "    \n",
    "print('Validation:')\n",
    "for batch in val_loader:\n",
    "    print('Input dimensions:', batch[0].shape)\n",
    "    print('Output dimensions:', batch[1].shape)\n",
    "\n",
    "print('Test:')    \n",
    "for batch in test_loader:\n",
    "    print('Input dimensions:', batch[0].shape)\n",
    "    print('Output dimensions:', batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, os, time\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "        input_height: int=500,\n",
    "        input_len: int=12,\n",
    "        batch_first: bool=True,  \n",
    "        output_len: int=75, \n",
    "        num_hidden: int=512):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.model_type = '1D-CNN'\n",
    "        \n",
    "        self.squeeze = nn.Sequential(\n",
    "            # Convert from 2D to 1D\n",
    "            nn.Conv2d(1, 32, kernel_size=(3, input_len), stride=1, padding=(1, 0)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            # Convolutional block\n",
    "            nn.Conv1d(32, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(512, 25, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "        \n",
    "        # input is torch.Size([2, 500, 12])\n",
    "        output = self.squeeze(src.unsqueeze(1)) # torch.Size([2, 16, 500, 1])\n",
    "        output = output.squeeze(3) # torch.Size([2, 16, 500])\n",
    "        \n",
    "        output1 = self.conv(output) # torch.Size([2, 25, 500])\n",
    "        output2 = self.conv(output) # torch.Size([2, 25, 500])\n",
    "        output3 = self.conv(output) # torch.Size([2, 25, 500])\n",
    "\n",
    "        final = torch.cat([output1, output2, output3], 1) # should be torch.Size([2, 75, 500])\n",
    "        \n",
    "        return final\n",
    "\n",
    "\n",
    "def train(model: nn.Module) -> None:\n",
    "    \n",
    "    model.train()  # turn on train mode\n",
    "    \n",
    "    total_loss = 0.\n",
    "    print('epochs : ', epoch)\n",
    "\n",
    "    for x, y in train_loader:\n",
    "\n",
    "        data, targets = x.to(device), y.to(device)\n",
    "        \n",
    "        output = model(data)\n",
    "\n",
    "        # need to fix\n",
    "        targets = targets.reshape(-1, 75)\n",
    "        loss = criterion(output, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss/batch_size\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
    "    \n",
    "    model.eval()  # turn on evaluation mode\n",
    "    \n",
    "    total_loss = 0.\n",
    "    batch_l = len(eval_data) # dim 0 = batch size\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in eval_data:\n",
    "            \n",
    "            data, targets = x.to(device), y.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "\n",
    "            # need to fix\n",
    "            targets = targets.reshape(-1, 75)\n",
    "            total_loss += criterion(output, targets).item()\n",
    "\n",
    "    return total_loss/batch_l\n",
    "\n",
    "\n",
    "def plotActTime(output: np.array) -> None:\n",
    "\n",
    "    plt.figure(figsize=(1, 10))\n",
    "\n",
    "    output = output.view(75,-1)\n",
    "\n",
    "    ActTime = output.detach().numpy()\n",
    "\n",
    "    # plot the Activation Time array\n",
    "    plt.imshow(ActTime, cmap='jet', interpolation='nearest', aspect='auto')\n",
    "    plt.title('Activation Time')\n",
    "    plt.colorbar()\n",
    "    plt.grid(visible=True, which='major', color='#666666', linestyle='-')\n",
    "    plt.minorticks_on()\n",
    "    # not xticks\n",
    "    plt.xticks([])\n",
    "    plt.grid(visible=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "model = SqueezeNet().to(device)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "t_loss = []\n",
    "v_loss = []\n",
    "\n",
    "with TemporaryDirectory() as tempdir:\n",
    "\n",
    "    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        #print('trainer is running wild')\n",
    "\n",
    "        tr_loss = train(model)\n",
    "        val_loss = evaluate(model, val_loader)\n",
    "\n",
    "        t_loss.append(tr_loss)\n",
    "        v_loss.append(val_loss)\n",
    "\n",
    "        elapsed = time.time() - epoch_start_time\n",
    "        print('-' * 89)\n",
    "        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
    "            f'valid loss {val_loss:5.2f} | ' f'train loss {tr_loss:5.2f}' )\n",
    "        print('-' * 89)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "        scheduler.step()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(5, 10))\n",
    "    ax = axes[0]\n",
    "    ax.plot(range(len(t_loss)), t_loss)\n",
    "    ax.set_ylabel('Training loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax = axes[1]\n",
    "    ax.plot(range(len(v_loss)), v_loss)\n",
    "    ax.set_ylabel('Validation loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "\n",
    "    model.load_state_dict(torch.load(best_model_params_path)) # load best model states\n",
    "\n",
    "    test_loss = evaluate(model, test_loader)\n",
    "\n",
    "    print('=' * 89)\n",
    "    print(f'| End of training | test loss {test_loss:5.2f}')\n",
    "    print('=' * 89)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3x9-nn",
   "language": "python",
   "name": "python3x9-nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
